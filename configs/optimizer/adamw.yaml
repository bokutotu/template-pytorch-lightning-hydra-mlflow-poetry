# @package optimizer

_target_: torch.optim.AdamW

params: ???
lr: ${lr}
betas: [0.9, 0.999]
eps: 1e-08
weight_decay: 0.01
amsgrad: False